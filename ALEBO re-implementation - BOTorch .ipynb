{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brown-charm",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overhead-brunei",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:10.938541Z",
     "start_time": "2021-02-17T09:54:08.361214Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "import botorch \n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from gpytorch.kernels.kernel import Kernel\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.test_functions.synthetic import SyntheticTestFunction\n",
    "\n",
    "from botorch.models import FixedNoiseGP, ModelListGP\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "from botorch.models.gp_regression import FixedNoiseGP\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "\n",
    "\n",
    "from ax.models.torch import alebo as alebo_implementation_ax\n",
    "from ax.models.random.alebo_initializer import ALEBOInitializer\n",
    "from ax.modelbridge.strategies.alebo import ALEBOStrategy\n",
    "\n",
    "from ax.models.torch_base import TorchModel\n",
    "\n",
    "\n",
    "from typing import Any, Callable, Dict, List, MutableMapping, Optional, Tuple, Union\n",
    "\n",
    "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-expense",
   "metadata": {},
   "source": [
    "# System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "single-interval",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:12.213045Z",
     "start_time": "2021-02-17T09:54:12.208054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.3\n",
      "1.3.1\n",
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(botorch.__version__)\n",
    "print(gpytorch.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-diary",
   "metadata": {},
   "source": [
    "# Problem\n",
    "I am trying to re-implement ALEBO in BOTorch, to easily implement features such as heteroscedastic GPs and sparse GPs.   \n",
    "I test my re-implementation against the Branin_100 function.   \n",
    "The AX version of ALEBO can achieve very good results on this function, as shown here:  \n",
    "https://github.com/facebookresearch/alebo/blob/master/quickstart.ipynb  \n",
    "I am trying to achieve similar performance (in speed, memory usage and minima location) with a BOTorch re-implementation.   \n",
    "\n",
    "I define the following helper functions below:\n",
    "1. Branin_100 function creation (inheriting from botorch.test_functions.synthetic.SyntheticTestFunction).   \n",
    "2. Branin_100_ALEBO_BOTorch wrapper (analogous to obj() here: https://botorch.org/tutorials/bo_with_warped_gp)   \n",
    "3. gen_projection (taken from ax.modelbridge.strategies.alebo https://github.com/facebook/Ax/blob/master/ax/modelbridge/strategies/alebo.py)\n",
    "4. generate_initial_data_Branin_100 (analogous to generate_initial_data() in above tutorial)   \n",
    "5. standardise_outputs (normalises outputs to have zero mean and standard deviation one).  \n",
    "6. initialize_model (analogous to initialize_model() in above tutorial)  \n",
    "7. update_random_observations_Branin_100 (analogous to update_random_observations() in above tutorial)  \n",
    "\n",
    "I then provide my BO loop in full, below. \n",
    "\n",
    "Note: I often name variables according to their dimensions, and if they're an array or tensor.   \n",
    "I had to change between dimensions and arrays/tensors often in the implementation, so I hope you can excuse this.   \n",
    "example_variable_D_x_n_array for instance, would be a variable of dimensions (D x N), and a numpy array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-citizenship",
   "metadata": {},
   "source": [
    "# Helper functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-enforcement",
   "metadata": {},
   "source": [
    "## Branin_100 function creation \n",
    "I can see that the Branin function is already implemented in botorch.test_functions.synthetic.SyntheticTestFunction. I make some simple edits to it, to create a Branin_100 function, which only has two dimensions of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-incidence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:13.927095Z",
     "start_time": "2021-02-17T09:54:13.921097Z"
    }
   },
   "outputs": [],
   "source": [
    "class Branin_100_Shaheen(SyntheticTestFunction):\n",
    "\n",
    "    dim = 100 # Edited dim to be 100 \n",
    "    _bounds = [(-5.0, 10.0), (0.0, 15.0)]*50 # Edited bounds for 100-dim function\n",
    "    _optimal_value = 0.397887\n",
    "    _optimizers = [(-math.pi, 12.275), (math.pi, 2.275), (9.42478, 2.475)]\n",
    "\n",
    "    def evaluate_true(self, X: Tensor) -> Tensor:\n",
    "        t1 = (\n",
    "            X[..., 1]\n",
    "            - 5.1 / (4 * math.pi ** 2) * X[..., 0] ** 2\n",
    "            + 5 / math.pi * X[..., 0]\n",
    "            - 6\n",
    "        )\n",
    "        t2 = 10 * (1 - 1 / (8 * math.pi)) * torch.cos(X[..., 0])\n",
    "        return t1 ** 2 + t2 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-rehabilitation",
   "metadata": {},
   "source": [
    "## Branin_100_ALEBO_BOTorch wrapper\n",
    "I wrap the Branin_100 function above, so I can input a set of sample points, train_x:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clinical-cleaners",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:14.684270Z",
     "start_time": "2021-02-17T09:54:14.680264Z"
    }
   },
   "outputs": [],
   "source": [
    "def Branin_100_ALEBO_BOTorch_wrapper(train_x):\n",
    "    branin_100_ = Branin_100_Shaheen(noise_std = 0.0, negate = False)\n",
    "    number_of_sample_points = train_x.shape[1]\n",
    "    fitness_values = np.zeros(shape=(number_of_sample_points))\n",
    "    \n",
    "    for i in range(0, number_of_sample_points):\n",
    "        param_set = train_x[:,i].T\n",
    "        # Convert param set to tensor, for input to evaluate_true on test function\n",
    "        param_set = torch.tensor(param_set)\n",
    "        fitness_values[i] = branin_100_.evaluate_true(X = param_set)\n",
    "\n",
    "    return fitness_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-equality",
   "metadata": {},
   "source": [
    "## gen_projection \n",
    "Lifted straight from ax.modelbridge.strategies.alebo, minus self parameter, as it was part of the ALEBOStrategy class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-yacht",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:15.507491Z",
     "start_time": "2021-02-17T09:54:15.504485Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_projection(d: int, D: int, dtype: torch.dtype, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Generate the projection matrix B as a (d x D) tensor\"\"\"\n",
    "    B0 = torch.randn(d, D, dtype=dtype, device=device)\n",
    "    B = B0 / torch.sqrt((B0 ** 2).sum(dim=0))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-cheese",
   "metadata": {},
   "source": [
    "## standardise_outputs\n",
    "I couldn't see any normalisation of the outputs, to aid the GP fitting, but I could be completely wrong here.   \n",
    "I implemented a rudimentary normalisation, taking the mean to zero and the standard deviation to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-cause",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:16.228156Z",
     "start_time": "2021-02-17T09:54:16.224158Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardise_outputs(outputs_vector):\n",
    "    mean_of_outputs = np.mean(outputs_vector)\n",
    "    std_dev_of_outputs = np.std(outputs_vector)\n",
    "    \n",
    "    outputs_vector -= mean_of_outputs\n",
    "    outputs_vector /= std_dev_of_outputs\n",
    "    \n",
    "    return outputs_vector, mean_of_outputs, std_dev_of_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-grave",
   "metadata": {},
   "source": [
    "## generate_initial_data_Branin_100\n",
    "In this function, I take a requested number of sample points, the projection matrix B, and output:\n",
    "1. The training sample points\n",
    "2. The normalised training objective values\n",
    "3. The best objective\n",
    "4. The training sample points, projected down to the embedding dimension \n",
    "5. The mean of the training objectives \n",
    "6. The standard deviation of the training objectives \n",
    "\n",
    "I use the ALEBOInitializer to generate these training sample points, which I think is used correctly, but I could be wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legendary-headline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:16.863165Z",
     "start_time": "2021-02-17T09:54:16.857174Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_initial_data_Branin_100(n, B: torch.Tensor):\n",
    "    # D = original dimensionality\n",
    "    # n = number of sample points\n",
    "    # d = embedding dimensionality\n",
    "    \n",
    "    # Initialize ALEBOInitializer\n",
    "    ALEBO_Initializer = ALEBOInitializer(B.cpu().numpy()) \n",
    "    \n",
    "    # Use ALEBOInitializer to generate initial sample points\n",
    "    train_x_n_x_D_array , __ = ALEBO_Initializer.gen(n = n, bounds=[(-1.0, 1.0)] * B.shape[1]) \n",
    "    \n",
    "    # Create train_x_n_x_D as a tensor, for torch.matmul with B\n",
    "    train_x_n_x_D_tensor = torch.from_numpy(train_x_n_x_D_array)\n",
    "\n",
    "    # Pass training data to Branin_100 wrapper, get objective values\n",
    "    exact_obj = Branin_100_ALEBO_BOTorch_wrapper(train_x_n_x_D_array.T)\n",
    "    exact_obj_n_x_1 = torch.tensor(exact_obj).unsqueeze(-1)\n",
    "    \n",
    "    # Normalise objective values \n",
    "    exact_obj_normalised, mean_of_initial_data, std_dev_of_initial_data = standardise_outputs(exact_obj)\n",
    "    train_obj_normalised = torch.tensor(exact_obj_normalised).unsqueeze(-1)  # add output dimension\n",
    "    \n",
    "    # Get best objective value, unnormalised\n",
    "    best_observed_value = exact_obj_n_x_1.min().item()\n",
    "    \n",
    "    # Project training data down to embedding dim \n",
    "    train_x_projected_down_d_x_n_tensor = torch.matmul(B, train_x_n_x_D_tensor.T)\n",
    "\n",
    "    # output training inputs, normalised training objectives, best objective, \n",
    "    #training inputs projected down, mean of training objectives, std. dev of training objectives\n",
    "    return train_x_n_x_D_tensor, train_obj_normalised, best_observed_value, train_x_projected_down_d_x_n_tensor, mean_of_initial_data, std_dev_of_initial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-extraction",
   "metadata": {},
   "source": [
    "## initialize_model \n",
    "Here, I needed to re-implement the initialize_model functions in the BOTorch tutorials.   \n",
    "Digging around the ALEBO code, I found the ALEBOGP class, which I instantiate with some parameters which again, I think should be correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "appointed-camera",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:17.646138Z",
     "start_time": "2021-02-17T09:54:17.641151Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_model(train_x_projected_down, train_obj, B, noise):\n",
    "    '''\n",
    "    Args from ALEBOGP:\n",
    "    B: (d x D) Projection matrix.\n",
    "    train_X: (n x d) X training data.\n",
    "    train_Y: (n x 1) Y training data.\n",
    "    train_Yvar: (n x 1) Noise variances of each training Y.\n",
    "    '''\n",
    "    dtype = torch.double\n",
    "    device = torch.device('cpu')\n",
    "    train_yvar = torch.tensor(noise**2, device=device, dtype=dtype)\n",
    "    model = alebo_implementation_ax.ALEBOGP(train_X = train_x_projected_down, \n",
    "                                            train_Y = train_obj, \n",
    "                                            train_Yvar = train_yvar.expand_as(train_obj), \n",
    "                                            B = B).to(train_x_projected_down) \n",
    "    \n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-brunei",
   "metadata": {},
   "source": [
    "## update_random_observations_Branin_100\n",
    "Here, I needed to replicate the random selection and execution of a sample point, as in the BOTorch tutorials, and used ALEBOInitializer to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "golden-subdivision",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:54:18.509548Z",
     "start_time": "2021-02-17T09:54:18.504556Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_random_observations_Branin_100(best_random):\n",
    "    \"\"\"Simulates a quasi-random policy by taking a the current list of best values observed randomly,\n",
    "    drawing a new random point, observing its value, and updating the list.\n",
    "    \"\"\"\n",
    "    ALEBO_Initializer = ALEBOInitializer(B.cpu().numpy())\n",
    "    rand_x_1_x_D , __ = ALEBO_Initializer.gen(n = 1, bounds=[(-1.0, 1.0)] * B.shape[1]) \n",
    "    rand_x_D_x_1 = rand_x_1_x_D.T\n",
    "    next_random_objective_value = torch.tensor(Branin_100_ALEBO_BOTorch_wrapper(rand_x_D_x_1)).unsqueeze(-1).min().item()\n",
    "    best_random.append(min(best_random[-1], next_random_objective_value))       \n",
    "    return best_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-wireless",
   "metadata": {},
   "source": [
    "# BO Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extreme-injection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:55:32.313742Z",
     "start_time": "2021-02-17T09:54:30.994235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial  1 of 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahe\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning:\n",
      "\n",
      "CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "\n",
      "[INFO 02-17 09:54:36] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n",
      "<ipython-input-10-0a0bff94dd06>:88: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:54:43] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:54:50] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 3\n",
      "\n",
      "Trial  2 of 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:54:54] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:55:00] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:55:07] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 3\n",
      "\n",
      "Trial  3 of 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:55:13] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:55:22] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-17 09:55:31] ax.models.torch.alebo: Generated sequential candidate 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached end of BO loop, iteration = 3\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS = 3\n",
    "N_BATCH = 15\n",
    "n_init = 5\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# I had to increase this from 0.1 to avoid numerical instabilities, but I think it may be affecting performance somewhat \n",
    "noise = 1.0\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.double\n",
    "\n",
    "# Initialise results lists for N_TRIALS\n",
    "best_observed_all, best_random_all = [], []\n",
    "\n",
    "# Create projection matrix B\n",
    "B = gen_projection(d = 2, D = 100, dtype = torch.double, device = 'cpu')\n",
    "\n",
    "# average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "    \n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    \n",
    "    # Initialise results list for N_BATCH\n",
    "    best_observed, best_random = [], []\n",
    "    \n",
    "    # Call helper function to generate initial training data\n",
    "    train_x, train_obj_normalised, best_observed_value, train_x_projected_down_d_x_n, mean_init_data, std_dev_init_data = generate_initial_data_Branin_100(n= n_init, B = B)\n",
    "\n",
    "    # Transpose training sample points projected down, for input to initialize_model\n",
    "    train_x_projected_down_n_x_d_tensor = train_x_projected_down_d_x_n.T \n",
    "    mll, model = initialize_model(train_x_projected_down_n_x_d_tensor, train_obj_normalised, B, noise = noise)\n",
    "\n",
    "    # Append best value from training data to results lists\n",
    "    best_observed.append(best_observed_value)\n",
    "    best_random.append(best_observed_value)\n",
    "    init_state_dict = model.state_dict()\n",
    "\n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_BATCH + 1):    \n",
    "                \n",
    "        # Fit ALEBO GP model\n",
    "        train_yvar = torch.tensor(noise**2, device = device, dtype = dtype)\n",
    "        m_b = alebo_implementation_ax.get_fitted_model(B = B, \n",
    "                               train_X = train_x_projected_down_n_x_d_tensor, \n",
    "                               train_Y = train_obj_normalised,\n",
    "                               train_Yvar = train_yvar.expand_as(train_obj_normalised),\n",
    "                               restarts = 20,\n",
    "                               nsamp = 512,\n",
    "                               init_state_dict = init_state_dict)\n",
    "        \n",
    "        # Get MLL for model \n",
    "        mll_fitted = ExactMarginalLogLikelihood(m_b.likelihood, m_b)\n",
    "        \n",
    "        # We use the NEI as our acquisition function. \n",
    "        Nei = qNoisyExpectedImprovement(model=m_b, X_baseline=train_x_projected_down_n_x_d_tensor)\n",
    "        \n",
    "        # Optimize acquisition function and get new observation\n",
    "        # Note, we use the alebo_acqf_optimizer, as defined in the ALEBO AX implementation\n",
    "        new_x_1_x_d_tensor, new_obj_tensor = alebo_implementation_ax.alebo_acqf_optimizer(Nei, \n",
    "                                                    bounds = [None, None],\n",
    "                                                    n = 1,\n",
    "                                                    raw_samples = 512,\n",
    "                                                    num_restarts = 20,\n",
    "                                                    B = B,\n",
    "                                                    inequality_constraints = None,\n",
    "                                                    fixed_features = None,\n",
    "                                                    rounding_func = None\n",
    "                                                    )\n",
    "        \n",
    "        \n",
    "        # Create pseudoinverse of B\n",
    "        pinv_B_D_x_d_array = np.linalg.pinv(B)\n",
    "\n",
    "        # Project new sample point, from embedding space to original space, via pseudoinverse of B\n",
    "        new_x_projected_up_D_x_1_array = pinv_B_D_x_d_array @ new_x_1_x_d_tensor.numpy().T\n",
    "\n",
    "        # Update training points in embedding space, with new point \n",
    "        train_x_projected_down_n_x_d_tensor = torch.cat([train_x_projected_down_n_x_d_tensor, new_x_1_x_d_tensor])\n",
    "        \n",
    "        # Project training data from embedding space, to original space, via pseudoinverse of B \n",
    "        train_x_projected_down_then_up_D_x_n_array = pinv_B_D_x_d_array @ train_x_projected_down_n_x_d_tensor.numpy().T\n",
    "        new_obj_projected_up = torch.tensor(Branin_100_ALEBO_BOTorch_wrapper(new_x_projected_up_D_x_1_array)).unsqueeze(-1)\n",
    "\n",
    "        # Normalise new objective value\n",
    "        new_obj_projected_up_normalised = (new_obj_projected_up - mean_init_data) / std_dev_init_data\n",
    "        \n",
    "        # Append the new (normalised) objective value to the other (normalised) objective values\n",
    "        train_obj_normalised = torch.cat([train_obj_normalised, torch.tensor(new_obj_projected_up_normalised)])\n",
    "\n",
    "        # Execute random sample point, append best value to best_random list\n",
    "        best_random = update_random_observations_Branin_100(best_random)\n",
    "                \n",
    "        # Get the best value amongst all the normalised objective values\n",
    "        best_value = train_obj_normalised.min().item()\n",
    "        \n",
    "        # Append the best value, amongst all normalised objectives, to the best_observed array\n",
    "        best_observed.append(best_value)\n",
    "        \n",
    "        # Retrain the GP model on the training sample points (plus new value), and training objectives (plus new value)\n",
    "        mll, model = initialize_model(train_x_projected_down_n_x_d_tensor, train_obj_normalised, B = B, noise = noise)\n",
    "        init_state_dict = model.state_dict()\n",
    "\n",
    "        print (f'reached end of BO loop, iteration = {iteration}')\n",
    "\n",
    "    best_observed_all.append(best_observed)\n",
    "    best_random_all.append(best_random)\n",
    "best_observed_all = (np.asarray(best_observed_all) * std_dev_init_data) + mean_init_data\n",
    "best_random_all = (np.asarray(best_random_all) * std_dev_init_data) + mean_init_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-classic",
   "metadata": {},
   "source": [
    "# Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funny-extraction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T09:56:10.465331Z",
     "start_time": "2021-02-17T09:56:10.253077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_observed_all = [[347.58068805  47.67579467  47.67579467  47.67579467]\n",
      " [316.81165869  44.55850973  44.55850973  44.55850973]\n",
      " [333.69846143  47.89994976  47.89994976  47.89994976]]\n",
      "best_random_all = [[347.58068805 347.58068805 339.61936621 339.61936621]\n",
      " [316.81165869 316.81165869 316.81165869 316.81165869]\n",
      " [333.69846143 333.69846143 333.69846143 333.69846143]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x225b7c2cd30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "\n",
    "print (f'best_observed_all = {best_observed_all}')\n",
    "print (f'best_random_all = {best_random_all}')\n",
    "\n",
    "iters = np.arange(N_BATCH + 1)\n",
    "y = np.asarray(best_observed_all)\n",
    "y_rnd =  np.asarray(best_random_all)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.errorbar(iters, y_rnd.mean(axis=0), yerr=ci(y_rnd), label=\"random\", linewidth=1.5, capsize=3, alpha=0.6)\n",
    "ax.errorbar(iters, y.mean(axis=0), yerr=ci(y), label=\"EI\", linewidth=1.5, capsize=3, alpha=0.6)\n",
    "ax.set(xlabel='number of observations (beyond initial points)', ylabel='Regret')\n",
    "ax.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-detection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-thumb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
